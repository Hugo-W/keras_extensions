from keras.models import Model, Sequential
from keras.preprocessing.image import ImageDataGenerator
from keras import optimizers, objectives
from keras import backend as K

class SingleLayerUnsupervised(Sequential):
    """
    Single layer unsupervised learning Model.
    """
    # add Layer, adapted from keras.models.Sequential
    def add(self, layer):
        if len(self.layers) > 0:
            warnings.warn('Cannot add more than one Layer to SingleLayerUnsupervised!')
            return
        super(SingleLayerUnsupervised, self).add(layer)

    # compile theano graph, adapted from keras.models.Sequential
    def compile(self, optimizer, loss):
        self.build()
        self.optimizer = optimizers.get(optimizer)

        self.loss = objectives.get(loss)

        # input of model
        #self.X_train = self.get_input(train=True)
        #self.X_test = self.get_input(train=False)
        self.X_train = self.input
        self.X_test = self.input

        train_loss = self.loss(self.X_train)
        test_loss = self.loss(self.X_test)

        train_loss.name = 'train_loss'
        test_loss.name = 'test_loss'
      

        for r in self.regularizers:
            train_loss = r(train_loss)
        updates = self.optimizer.get_updates(self.trainable_weights, self.constraints, train_loss)
        updates += self.updates

        if type(self.X_train) == list:
            train_ins = self.X_train
            test_ins = self.X_test
        else:
            train_ins = [self.X_train]
            test_ins = [self.X_test]

        self._train = K.function(train_ins, train_loss, updates=updates)
        self._test = K.function(test_ins, test_loss)

    # train model, adapted from keras.models.Sequential
    def fit(self, X, batch_size=128, nb_epoch=100, verbose=1, callbacks=[],
            validation_split=0., validation_data=None, shuffle=True, show_accuracy=False):

        idg = ImageDataGenerator(zca_whitening=False, featurewise_center=True, featurewise_std_normalization=True)
        idg.fit(X)
        X = idg.standardize(X.copy())
        #X = standardize_X(X)

        val_f = None
        val_ins = None
        if validation_data or validation_split:
            val_ins = X # Hugo...
            if show_accuracy:
                val_f = self._test_with_acc
            else:
                val_f = self._test

        if show_accuracy:
            f = self._train_with_acc
            out_labels = ['loss', 'acc']
        else:
            f = self._train
            out_labels = ['loss']

        ins = X# + [y, sample_weight]
        #metrics = ['loss', 'acc', 'val_loss', 'val_acc']
        metrics = ['loss', 'acc']
        return self._fit_loop(f, [ins], out_labels=out_labels, batch_size=batch_size, nb_epoch=nb_epoch,
                         verbose=verbose, callbacks=callbacks,
                         val_f=val_f, val_ins=val_ins,
                         shuffle=shuffle, callback_metrics=metrics)

